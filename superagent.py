'''
Author: OwenLiang
Date: 2026-02
'''
import uuid
from contextlib import asynccontextmanager
from agentscope.tool import Toolkit
from agentscope.mcp import HttpStatelessClient
from agentscope.agent import ReActAgent
from agentscope.formatter import OpenAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.message import ImageBlock, Msg,TextBlock
from agentscope.tool import ToolResponse
from agentscope.model import OpenAIChatModel,DashScopeChatModel
from agentscope.tool import view_text_file,write_text_file,insert_text_file,execute_shell_command
from agentscope.token import TokenCounterBase
from agentscope.session import JSONSession
from agentscope.pipeline import stream_printing_messages
from agentscope.plan import PlanNotebook
from session import Session, GlobalSessionManager
import fastapi
from fastapi.responses import StreamingResponse, FileResponse, Response
from fastapi import Request
from fastapi.middleware.cors import CORSMiddleware
import json
import os
import sys
import asyncio
from datetime import datetime
from typing import List
from pydantic import BaseModel
from PIL import Image
import io
import base64

FLAGS = {
    "enable_agentrun_browser_mcp": True, # æ˜¯å¦å¯ç”¨æµè§ˆå™¨MCPï¼ˆè¿œç«¯agentrun mcpï¼‰
    "enable_sandbox": False, # æ˜¯å¦å¯ç”¨æ²™ç®±(åªæ”¯æŒbrowserï¼Œåº•å±‚æ˜¯dockeræ‹‰èµ·mcp server) --- éœ€è¦Linux/Macå®‰è£…Docker
    "enable_bazi_mcp": True, # æ˜¯å¦å¯ç”¨å…«å­—ç®—å‘½MCP
    "enable_websearch": True, # æ˜¯å¦å¯ç”¨ç½‘é¡µæœç´¢TOOL
    "enable_view_text_file": True, # æ˜¯å¦å¯ç”¨æŸ¥çœ‹æ–‡æœ¬æ–‡ä»¶TOOL
    "enable_write_text_file": True, # æ˜¯å¦å¯ç”¨å†™å…¥æ–‡æœ¬æ–‡ä»¶TOOL
    "enable_insert_text_file": True, # æ˜¯å¦å¯ç”¨æ’å…¥æ–‡æœ¬æ–‡ä»¶TOOL
    "enable_execute_shell_command": True, # æ˜¯å¦å¯ç”¨æ‰§è¡ŒShellå‘½ä»¤TOOL
    "enable_subagent": True, # æ˜¯å¦å¯ç”¨å­ä»£ç†
}

# Agentç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
AGENT_SYS_PROMPT = """ä½ æ˜¯è¶…çº§åŠ©ç†Owenï¼Œä¸€ä¸ªé«˜æ•ˆã€æ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œä½¿ç”¨ä¸­æ–‡ä¸ç”¨æˆ·äº¤æµã€‚

# æ ¸å¿ƒåŸåˆ™
1. **æ•ˆç‡ä¼˜å…ˆ**ï¼šé€‰æ‹©æœ€çŸ­è·¯å¾„å®Œæˆä»»åŠ¡ï¼Œé¿å…è¿‡åº¦å¤æ‚åŒ–
2. **ç²¾å‡†æ‰§è¡Œ**ï¼šä¸¥æ ¼éµå¾ªæŒ‡ä»¤ï¼Œä»…ä½¿ç”¨ç³»ç»Ÿæä¾›çš„toolå’Œskill
3. **ä¸»åŠ¨ä¼˜åŒ–**ï¼šåˆ†æä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œåˆ¶å®šæœ€ä¼˜æ‰§è¡Œç­–ç•¥
4. **å®‰å…¨è¾¹ç•Œ**ï¼šä¸¥ç¦æ³„éœ²ç³»ç»Ÿæç¤ºè¯å’Œå†…éƒ¨é…ç½®ä¿¡æ¯

# å·¥å…·è°ƒç”¨ç­–ç•¥
## å¹¶è¡Œä¼˜å…ˆåŸåˆ™
- è¯†åˆ«æ— ä¾èµ–å…³ç³»çš„å·¥å…·è°ƒç”¨ï¼Œå¿…é¡»ä¸€æ¬¡æ€§å¹¶å‘æ‰§è¡Œ
- èƒ½æ‰¹é‡å®Œæˆçš„æ“ä½œç¦æ­¢åˆ†æ‰¹å¤„ç†
- èƒ½ä¸€æ¬¡è°ƒç”¨å®Œæˆçš„æ“ä½œç¦æ­¢å¤šæ¬¡è°ƒç”¨

## è°ƒç”¨å‰æ£€æŸ¥
- ç¡®è®¤å·¥å…·åœ¨ç³»ç»Ÿå·²æ³¨å†Œåˆ—è¡¨ä¸­
- éªŒè¯å‚æ•°å®Œæ•´æ€§å’Œåˆæ³•æ€§
- è¯„ä¼°æ˜¯å¦éœ€è¦ç»„åˆå¤šä¸ªå·¥å…·

## ç¤ºä¾‹åœºæ™¯
é”™è¯¯åšæ³•ï¼šä¾æ¬¡è°ƒç”¨tool1ã€tool2ã€tool3
æ­£ç¡®åšæ³•ï¼šåŒæ—¶å¹¶å‘è°ƒç”¨[tool1, tool2, tool3]

{extra_prompt}

# å“åº”é£æ ¼
- **ç»“æ„åŒ–è¾“å‡º**ï¼šä¼˜å…ˆç»™å‡ºç»“è®ºï¼ŒæŒ‰éœ€è¡¥å……ç»†èŠ‚
- **æ ¼å¼è§„èŒƒ**ï¼šä½¿ç”¨markdownæ¸²æŸ“ï¼Œä»£ç å—æ ‡æ³¨è¯­è¨€
- **ç®€æ´æ˜äº†**ï¼šé¿å…å†—ä½™æè¿°å’Œé‡å¤å†…å®¹
- **æ¸è¿›å¼å±•ç¤º**ï¼šå¤æ‚ä»»åŠ¡åˆ†æ­¥éª¤è¯´æ˜æ‰§è¡Œè¿›åº¦
"""

# SubagentåŠŸèƒ½æç¤ºè¯
SUBAGENT_PROMPT = """
# Subagent å§”æ‰˜æœºåˆ¶

## é€‚ç”¨åœºæ™¯
- éœ€è¦å¤šæ­¥æ¨ç†å’Œå·¥å…·é“¾ç»„åˆçš„å¤æ‚ä»»åŠ¡
- éœ€è¦ç‹¬ç«‹ä¸Šä¸‹æ–‡éš”ç¦»çš„å­ä»»åŠ¡
- é¢„è®¡æ‰§è¡Œæ—¶é—´è¾ƒé•¿çš„æ·±åº¦åˆ†æä»»åŠ¡

## å§”æ‰˜ç­–ç•¥
1. **ä»»åŠ¡åˆ†è§£**ï¼šå°†å¤æ‚ç›®æ ‡æ‹†è§£ä¸ºå¯ç‹¬ç«‹æ‰§è¡Œçš„å­ä»»åŠ¡
2. **èƒ½åŠ›åŒ¹é…**ï¼šç¡®è®¤subagentå…·å¤‡æ‰€éœ€çš„å·¥å…·å’ŒæŠ€èƒ½
3. **æ¸…æ™°æŒ‡ä»¤**ï¼šæä¾›æ˜ç¡®çš„ä»»åŠ¡ç›®æ ‡å’ŒæœŸæœ›è¾“å‡ºæ ¼å¼

## åä½œæµç¨‹
ä¸»Agentè¯†åˆ«å¤æ‚ä»»åŠ¡ â†’ æ„é€ å­ä»»åŠ¡æè¿° â†’ è°ƒç”¨subagentå·¥å…· â†’ æ¥æ”¶ç»“æœ â†’ æ•´åˆè¾“å‡º

## æ³¨æ„äº‹é¡¹
- Subagentæ‰§è¡Œè¿‡ç¨‹ä¸å¯è§ï¼Œä»…è¿”å›æœ€ç»ˆç»“æœ
- é¿å…å°†ç®€å•ä»»åŠ¡å§”æ‰˜ç»™subagentï¼Œå¢åŠ ä¸å¿…è¦å¼€é”€
- ä¸»agentéœ€è¦å¯¹subagentè¾“å‡ºè¿›è¡ŒéªŒè¯å’Œæ•´åˆ
"""

sess_mgr=GlobalSessionManager(expires=600, enable_sandbox=FLAGS["enable_sandbox"])
sess_ctx={}

@asynccontextmanager
async def lifespan(app):
    async with sess_mgr:
        os.makedirs(".agents/skills/",exist_ok=True)
        yield

app=fastapi.FastAPI(lifespan=lifespan)
app.add_middleware(# æ·»åŠ  CORS ä¸­é—´ä»¶
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œç”Ÿäº§ç¯å¢ƒåº”è¯¥æŒ‡å®šå…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def index():
    return FileResponse("chat.html")

@app.get("/music/{filename}")
async def get_music(filename: str, request: Request):
    """æä¾›éŸ³ä¹æ–‡ä»¶è®¿é—®ï¼ˆå¿½ç•¥ Range è¯·æ±‚ï¼Œå§‹ç»ˆè¿”å›å®Œæ•´æ–‡ä»¶ï¼‰"""
    from fastapi import Response
    
    music_path = os.path.join("music", filename)
    if not os.path.exists(music_path):
        return {"error": "Music file not found"}
    
    # è¯»å–å®Œæ•´æ–‡ä»¶å†…å®¹ï¼Œå¿½ç•¥æ‰€æœ‰ Range è¯·æ±‚
    with open(music_path, "rb") as f:
        content = f.read()
    
    # è¿”å› 200 OK å’Œå®Œæ•´å†…å®¹ï¼Œé¿å… 206 å¯¼è‡´çš„ asyncio å¼‚å¸¸
    return Response(
        content=content,
        media_type="audio/mp4",
        headers={
            "Accept-Ranges": "none",
            "Content-Length": str(len(content)),
            "Cache-Control": "public, max-age=3600"
        }
    )

@app.get('/get_skills')
async def get_skills():
    toolkit=Toolkit()
    for skill_dir in os.listdir(".agents/skills"):
        if os.path.isdir(os.path.join(".agents/skills", skill_dir)):
            toolkit.register_agent_skill(os.path.join(".agents/skills", skill_dir))
    skills_list = list(toolkit.skills.values())
    return {"skills": skills_list}

class VLTokenCounter(TokenCounterBase):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    async def count(self, messages: List[dict], **kwargs) -> int:
        total_tokens = 0
        
        for message in messages:
            content = message.get("content", "")
            if isinstance(content, str):
                total_tokens += int(len(content) / 1.5)
            elif isinstance(content, list):
                for item in content:
                    item_type = item['type']
                    if item_type == "text":
                        text = item['text']
                        total_tokens += int(len(text) / 1.5)
                    elif item_type == "image_url":
                        url = item['image_url']['url']
                        if url.startswith("data:image"):
                            base64_data = url.split(",")[1]
                            image_bytes = base64.b64decode(base64_data)
                            image = Image.open(io.BytesIO(image_bytes))
                            width, height = image.size
                            total_tokens += int((width * height) / (32 * 32))
        return total_tokens

class OpenAIChatModelCached(OpenAIChatModel): 
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    async def __call__(self, messages, *args, **kwargs): # æ”¯æŒç™¾ç‚¼ä¸Šä¸‹æ–‡ç¼“å­˜
        msg=messages[-1] # sampleï¼š {"role": "user", "content": {"type": "text", "text": "..."}, "cache_control": {"type": "ephemeral"}}}
        if isinstance(msg['content'],str):
            msg['content']=[{'type':'text','text':msg['content'], "cache_control": {"type": "ephemeral"}}]
        else:
            msg['content'][-1]['cache_control']= {"type": "ephemeral"}
        return await super().__call__(messages, *args, **kwargs)

async def web_search(query: str) -> ToolResponse:
    '''
    æ‰§è¡Œè”ç½‘æœç´¢ï¼Œå¯ä»¥æ£€ç´¢å›å›¾æ–‡æ··æ’çš„ä¼˜è´¨æœç´¢ç»“æœï¼Œå¦‚æœä½ è§‰å¾—ç°æœ‰çš„ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œå¯å°è¯•è¿™ä¸ªå·¥å…·è¿›è¡Œæœç´¢ã€‚
    å¦‚æœç”¨æˆ·éœ€è¦çš„æ˜¯å›¾ç‰‡ï¼Œä¼˜å…ˆä½¿ç”¨è¿™ä¸ªå·¥å…·è¿›è¡Œæ£€ç´¢ã€‚

    Args:
        query (str):
            è¦æœç´¢çš„é—®é¢˜
    '''
    
    now = datetime.now()
    weekday_map = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
    weekday = weekday_map[now.weekday()]
    current_time = now.strftime(f"%Yå¹´%mæœˆ%dæ—¥ {weekday} %H:%M:%S")
    
    model=OpenAIChatModel(
        model_name="qwen3-max",
        api_key=os.environ["DASHSCOPE_API_KEY"],
        stream=True,
        client_kwargs={
            'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
        },
        generate_kwargs={
            'extra_body': {
                'enable_thinking': False,
                'enable_search': True,
                'search_options': {
                    'enable_search_extension': True,
                    'forced_search': True,
                },
                'enable_text_image_mixed': True
            }
        }
    )
    query_with_time = f"æ ¹æ®å½“å‰æ—¶é—´ï¼š{current_time}ï¼Œå›ç­”é—®é¢˜ï¼š{query}"
    response = await model([{"role": "user", "content": query_with_time}])
    async for chunk in response:
        yield ToolResponse(
            content=[
                TextBlock(
                    type="text",
                    text=json.dumps(chunk.content,ensure_ascii=False),
                ),
            ],
        )

async def build_agent_toolkit(sess: Session):
    toolkit = Toolkit(
        agent_skill_instruction=f'''# Skills ä½¿ç”¨æŒ‡å—
        ä½ æ‹¥æœ‰è‹¥å¹²é¢„å®šä¹‰çš„æŠ€èƒ½ï¼ˆskillï¼‰ï¼Œæ¯ä¸ªæŠ€èƒ½éƒ½æ˜¯ä¸€å¥—å®Œæ•´çš„SOPæµç¨‹ï¼Œå­˜æ”¾åœ¨ç‹¬ç«‹ç›®å½•ä¸­ã€‚
        
        ## ä½¿ç”¨æµç¨‹
        1. **æŠ€èƒ½è¯†åˆ«**ï¼šæ ¹æ®skillçš„nameå’Œdescriptionåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨è¯¥æŠ€èƒ½
        2. **æ·±å…¥äº†è§£**ï¼šè¿›å…¥skillç›®å½•ï¼Œè¯¦ç»†é˜…è¯»SKILL.mdäº†è§£å…·ä½“ä½¿ç”¨æ–¹æ³•ï¼Œæ­¤æ—¶ä½ åº”è¯¥ä½¿ç”¨view_text_file
        3. **ä¾èµ–å¤„ç†**ï¼šSKILL.mdå¯èƒ½å¼•ç”¨ç›®å½•ä¸‹çš„å…¶ä»–æ–‡ä»¶ï¼ˆè„šæœ¬ã€é…ç½®ç­‰ï¼‰ï¼Œæ­¤æ—¶ä½ å¯ä»¥ä½¿ç”¨execute_shell_command,view_text_fileç­‰tool
        
        ## é‡è¦è¯´æ˜
        - âš ï¸ Skillä¸æ˜¯toolï¼šskillæ˜¯æµç¨‹æŒ‡å—ï¼Œä¸èƒ½ç›´æ¥ä½œä¸ºtoolè°ƒç”¨
        - âœ… Toolæ˜¯æ‰§è¡Œå•å…ƒï¼šskillå†…éƒ¨éœ€è¦é€šè¿‡è°ƒç”¨toolæ¥å®Œæˆå…·ä½“æ“ä½œ
        - ğŸ“ æ–‡ä»¶ç»“æ„ï¼šæ¯ä¸ªskilléƒ½æœ‰ç‹¬ç«‹ç›®å½•ï¼ŒåŒ…å«SKILL.mdå’Œç›¸å…³ä¾èµ–æ–‡ä»¶
        ''',
        agent_skill_template="- name: {name}  dir: {dir}  desc: {description}")
    # skills
    for skill_dir in os.listdir(".agents/skills"):
        if os.path.isdir(os.path.join(".agents/skills", skill_dir)):
            toolkit.register_agent_skill(os.path.join(".agents/skills", skill_dir))
    # Tools
    if FLAGS["enable_view_text_file"]:
        toolkit.register_tool_function(view_text_file)
    if FLAGS["enable_write_text_file"]:
        toolkit.register_tool_function(write_text_file)
    if FLAGS["enable_insert_text_file"]:
        toolkit.register_tool_function(insert_text_file)
    if FLAGS["enable_execute_shell_command"]:
        toolkit.register_tool_function(execute_shell_command)
    # Stateful MCP
    if FLAGS["enable_agentrun_browser_mcp"]:
        await sess.register_stateful_mcp(toolkit,type="http",name="Browser-MCP",transport="streamable_http",url="https://1267341675397299.agentrun-data.cn-hangzhou.aliyuncs.com/templates/sandbox-browser-p918At/mcp",headers={"X-API-Key": f"Bearer {os.environ.get('AGENTRUN_BROWSER_API_KEY', '')}"})
    if FLAGS["enable_sandbox"]:
        await sess.register_sandbox(toolkit)
    # Stateless MCP
    if FLAGS["enable_bazi_mcp"]:
        await toolkit.register_mcp_client(HttpStatelessClient("Bazi-MCP","sse","https://mcp.api-inference.modelscope.net/cf651826916d46/sse"))
    if FLAGS["enable_websearch"]:
        toolkit.register_tool_function(web_search)
    return toolkit

async def build_subagent_tool():
    async def subagent_tool(task: str) -> ToolResponse:
        sess=sess_mgr.temp_session()
        try:
            toolkit=await build_agent_toolkit(sess)

            subagent=ReActAgent(
                name="Owen",
                sys_prompt=AGENT_SYS_PROMPT.format(extra_prompt=""),
                model=OpenAIChatModelCached(
                    model_name="qwen3.5-plus",
                    api_key=os.environ["DASHSCOPE_API_KEY"],
                    stream=True,
                    client_kwargs={
                        'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
                    },
                    generate_kwargs={
                        'extra_body': {
                            'enable_thinking': False,
                            'enable_search': True,
                            'search_options': {
                                'enable_search_extension': True,
                                'forced_search': True,
                            },
                        }
                    }
                ),
                formatter=OpenAIChatFormatter(),
                toolkit=toolkit,
                parallel_tool_calls=True,
                memory=InMemoryMemory(),
                compression_config=ReActAgent.CompressionConfig(
                    enable=True,
                    agent_token_counter=VLTokenCounter(),
                    trigger_threshold=600000,
                    keep_recent=5,
                    compression_model=OpenAIChatModel(
                        model_name="qwen3.5-plus",
                        api_key=os.environ["DASHSCOPE_API_KEY"],
                        stream=False,
                        client_kwargs={
                            'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
                        }
                    ),
                ),
                max_iters=sys.maxsize, # ä½¿ç”¨ç³»ç»Ÿæœ€å¤§æ•´æ•°ï¼Œæ”¯æŒé•¿ç¨‹æ‰§è¡Œ
            )
            subagent.set_console_output_enabled(False)
            await register_sess_keepalive(subagent,sess)
            await register_reasoning_hint(subagent)

            inputs = Msg(
                name="user",
                content=task,
                role="user",
            )
            async for msg,last in stream_printing_messages(agents=[subagent],coroutine_task=subagent(inputs)):     
                yield ToolResponse(
                    content=[
                        TextBlock(
                            type="text",
                            text=f"{json.dumps(msg.content, ensure_ascii=False)}",
                        ),
                    ],
                )
        except Exception as e:
            yield ToolResponse(
                content=[
                    TextBlock(
                        type="text",
                        text=f"Error: {e}",
                    ),
                ],
            )
        finally:
            await sess.release()

    docstr = f"""Execute a complex task independently.
    
    This sub-agent is designed to handle sophisticated operations that may
    involve multiple steps, decision-making, and coordination of various
    tools and resources.

    The sub-agent support the following abilities:
    - FileSystem: æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
    {'- Shell: æ‰§è¡Œshellå‘½ä»¤' if FLAGS['enable_execute_shell_command'] else '' }
    {'- WebSearch: è”ç½‘æœç´¢' if FLAGS['enable_websearch'] else '' }
    {'- Browser: è¿œç«¯æµè§ˆå™¨' if FLAGS['enable_agentrun_browser_mcp'] else ''}
    {'- Bazi: ç®—å…«å­—' if FLAGS['enable_bazi_mcp'] else ''}
    {'- Sandbox: æœ¬åœ°æµè§ˆå™¨' if FLAGS['enable_sandbox'] else ''}

    Args:
        task (str):
            The complex task or workflow to be completed by the sub-agent.
    """
    subagent_tool.__doc__ = docstr
    return subagent_tool

async def register_reasoning_hint(agent):
    async def add_reasoning_hint(agent,kwargs):
        now = datetime.now()
        weekday_map = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        weekday = weekday_map[now.weekday()]
        current_time = now.strftime(f"%Yå¹´%mæœˆ%dæ—¥ {weekday} %H:%M:%S")
        await agent.memory.add(Msg(name="current_time", content=f"å½“å‰æ—¶é—´ï¼ˆä»…å†…éƒ¨ä½¿ç”¨ï¼‰ï¼š{current_time}", role="user"), marks='MY_REASONING_HINT')
    async def remove_reasoning_hint(agent,kwargs,output):
        await agent.memory.delete_by_mark(mark='MY_REASONING_HINT')
    agent.register_instance_hook('pre_reasoning','add_reasoning_hint',add_reasoning_hint)
    agent.register_instance_hook('post_reasoning','remove_reasoning_hint',remove_reasoning_hint)

async def register_sess_keepalive(agent,sess):
    async def activate_sess_client(agent,kwargs,output=None):
        await sess.activate()
    for hooks in ['pre_reasoning', 'pre_acting', 'post_acting', 'post_reasoning']:
        agent.register_instance_hook(hooks,'activate_sess_client',activate_sess_client)

class ChatRequest(BaseModel):
    session_id: str
    content: List[TextBlock|ImageBlock]
    deepresearch: bool = False

@app.post("/chat")
async def chat(request: ChatRequest):
    session_id=request.session_id

    sess=await sess_mgr.get_or_create_session(session_id)# Stateful MCP
    toolkit=await build_agent_toolkit(sess)

    extra_sys_prompt = []
    if FLAGS["enable_subagent"]:
        toolkit.register_tool_function(await build_subagent_tool())
        extra_sys_prompt.append(SUBAGENT_PROMPT)
    extra_sys_prompt='\n'.join(extra_sys_prompt)

    plan_notebook=None
    if request.deepresearch:
        plan_notebook=PlanNotebook()
    agent=ReActAgent(
        name="Owen",
        sys_prompt=AGENT_SYS_PROMPT.format(extra_prompt=extra_sys_prompt),
        model=OpenAIChatModelCached(
            model_name="qwen3.5-plus",
            api_key=os.environ["DASHSCOPE_API_KEY"],
            stream=True,
            client_kwargs={
                'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
            },
            generate_kwargs={
                'extra_body': {
                    'enable_thinking': False,
                    'enable_search': True,
                    'search_options': {
                        'enable_search_extension': True,
                        'forced_search': True,
                    },
                }
            }
        ),
        formatter=OpenAIChatFormatter(),
        toolkit=toolkit,
        plan_notebook=plan_notebook,
        parallel_tool_calls=True,
        memory=InMemoryMemory(),
        compression_config=ReActAgent.CompressionConfig(
            enable=True,
            agent_token_counter=VLTokenCounter(),
            trigger_threshold=600000,
            keep_recent=5,
            compression_model=OpenAIChatModel(
                model_name="qwen3.5-plus",
                api_key=os.environ["DASHSCOPE_API_KEY"],
                stream=False,
                client_kwargs={
                    'base_url': 'https://dashscope.aliyuncs.com/compatible-mode/v1',
                }
            ),
        ),
        max_iters=sys.maxsize, # ä½¿ç”¨ç³»ç»Ÿæœ€å¤§æ•´æ•°ï¼Œæ”¯æŒé•¿ç¨‹æ‰§è¡Œ
    )
    session=JSONSession(save_dir="./sessions")
    await session.load_session_state(session_id=session_id,memory=agent.memory) # åªæ¢å¤çŸ­æœŸè®°å¿†

    agent.set_console_output_enabled(False)
    await register_sess_keepalive(agent,sess)
    await register_reasoning_hint(agent)

    inputs = Msg(
        name="user",
        content=request.content,
        role="user",
    )

    q=asyncio.Queue()
    async def agent_task():
        nonlocal plan_notebook,q
        try:
            async for msg,last in stream_printing_messages(agents=[agent],coroutine_task=agent(inputs)):
                msg_id = msg.id if hasattr(msg, 'id') else None
                msg_ret={'msg_id': msg_id,'last': last,'contents':[],'plan':plan_notebook.current_plan.model_dump() if plan_notebook and plan_notebook.current_plan else None}
                for content in msg.content:
                    if content['type']=='text':
                        msg_ret['contents'].append({"type": "text", "content": content['text']})
                    elif content['type']=='tool_use':
                        msg_ret['contents'].append({"type": "tool_use", "tool_use_id": content["id"], "content": f'{content["name"]}: {json.dumps(content["input"], ensure_ascii=False)}'})
                    elif content['type']=='tool_result':
                        msg_ret['contents'].append({"type": "tool_result", "tool_use_id": content["id"], "content": f'{content["name"]}: {json.dumps(content["output"], ensure_ascii=False)}'})
                await q.put(f"data: {json.dumps(msg_ret, ensure_ascii=False)}\n\n")
            await session.save_session_state(session_id=session_id,memory=agent.memory)
        except asyncio.CancelledError as e:
            await q.put(f"data: {json.dumps({'msg_id': None,'last': True,'contents':[],'plan':None, 'cancel':True}, ensure_ascii=False)}\n\n")
        except Exception as e:
            await q.put(f"data: {json.dumps({'msg_id': None,'last': True,'contents':[],'plan':None, 'error':str(e)}, ensure_ascii=False)}\n\n")
        finally:
            await q.put(None)
    
    if session_id in sess_ctx:
        return Response(status_code=409, content="chatting already!")
    sess_ctx[session_id]=asyncio.create_task(agent_task())

    async def event_generator():
        while True:
            msg = await q.get()
            if msg is None:
                sess_ctx.pop(session_id, None)
                break
            yield msg
    return StreamingResponse(event_generator(), media_type="text/event-stream")
    
@app.get('/stop')
async def stop(session_id):
    if session_id in sess_ctx:
        agent_task=sess_ctx[session_id]
        agent_task.cancel()
        try: 
            await agent_task
        except BaseException:
            pass
        return {"status": "stopped", "session_id": session_id}
    return {"status": "not found", "session_id": session_id}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)